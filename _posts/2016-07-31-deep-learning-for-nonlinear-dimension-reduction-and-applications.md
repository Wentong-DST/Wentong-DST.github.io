---
layout: post
title:  "Deep learning for nonlinear dimension reduction and applications."
date:   2016-07-31 00:00:00 +0800
author: Mark N
categories:
---

I spent a significant proportion of my summer holidays completing yet another undergraduate research project (UROPS) in NUS, this time under the supervision of [<u>Alexandre THIERY</u>](http://www.normalesup.org/~athiery/). The research topic was deep learning and applications; following recent papers/articles (see references) concerning classification problems, autoencoders and modelling uncertainty in neural networks.

Here's the [<u>full paper</u>](/pdf/st3288.pdf "st3288.pdf") summarizing this project, as well as links to relevant code repositories:

* [<u>https://github.com/mollymr305/iris-classification</u>](https://github.com/mollymr305/iris-classification)
* [<u>https://github.com/mollymr305/stochastic-depth</u>](https://github.com/mollymr305/stochastic-depth)
* [<u>https://github.com/mollymr305/mnist-classification</u>](https://github.com/mollymr305/mnist-classification)
* [<u>https://github.com/mollymr305/mnist-autoencoder</u>](https://github.com/mollymr305/mnist-autoencoder)
* [<u>https://github.com/mollymr305/mnist-mc-dropout</u>](https://github.com/mollymr305/mnist-mc-dropout)

This was actually my first time doing anything related to machine learning -- I was always aware of the field but never really studied it detail. To be honest, I was really quite amazed at advancements in this field so far. Also, having a decent mathematics and computer science background definitely helped a lot.

### Selected References

**[1]** [<u>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</u>](https://arxiv.org/abs/1502.03167)

**[2]** [<u>Deep Residual Learning for Image Recognition</u>](https://arxiv.org/abs/1512.03385)

**[3]** [<u>Deep Networks with Stochastic Depth</u>](https://arxiv.org/abs/1603.09382)

**[4]** [<u>Nikhil Buduma, The Curse of Dimensionality and the Autoencoder</u>](http://nikhilbuduma.com/2015/03/10/the-curse-of-dimensionality/)

**[5]** [<u>Tutorial on Variational Autoencoders</u>](https://arxiv.org/abs/1606.05908)

**[6]** [<u>Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</u>](https://arxiv.org/abs/1506.02142)

**[7]** [<u>Dropout as a Bayesian Approximation: Appendix</u>](https://arxiv.org/abs/1506.02157)
